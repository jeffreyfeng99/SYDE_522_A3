{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extract_data_parameters.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCILJdPMNd5IQrr6aVKb6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffreyfeng99/SYDE_522_A3/blob/master/extract_data_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9UL7_2JANUn5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Function\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision import models\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOeAouEENftk",
        "outputId": "92cfe05e-4fe9-4c88-e75f-4c4491b0b1a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "IMAGE_SIZE = 224 #227"
      ],
      "metadata": {
        "id": "7fsqz3xdNhYk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = '/content/drive/MyDrive/4B/SYDE-522/data'\n",
        "output_root = '/content/drive/MyDrive/4B/SYDE-522/submission/03292022_resnetnorm'\n",
        "source_dataset_name = 'train_set'\n",
        "target_dataset_name = 'test_set'\n",
        "\n",
        "source_image_root = os.path.join(dataset_root, source_dataset_name)\n",
        "target_image_root = os.path.join(dataset_root, target_dataset_name)\n",
        "\n",
        "train_label_list = os.path.join(dataset_root, 'train_labels.csv')\n",
        "\n",
        "os.makedirs(output_root, exist_ok=True)"
      ],
      "metadata": {
        "id": "SxsvfTSoNjeB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetLoader(data.Dataset):\n",
        "    def __init__(self, data_root, data_list=None, transform=None):\n",
        "        self.root = data_root\n",
        "        self.transform = transform\n",
        "\n",
        "        # we only pass data_list if it's training set\n",
        "        if data_list is not None:\n",
        "            df = pd.read_csv(data_list)\n",
        "            self.img_paths = df['dir'].to_list()\n",
        "\n",
        "            if 'label2' in df.columns:\n",
        "                self.img_labels = df['label2'].to_list()\n",
        "            else: \n",
        "                self.img_labels = ['0' for i in range(len(self.img_paths))]\n",
        "\n",
        "            if 'label1' in df.columns:\n",
        "                self.domain_labels = df['label1'].to_list()\n",
        "            else: \n",
        "                self.domain_labels = ['0' for i in range(len(self.img_paths))]\n",
        "        else:\n",
        "            # Walk through test folder - we don't need labels\n",
        "            self.img_paths = [f for root,dirs,files in os.walk(data_root) for f in files if f.endswith('.png')]\n",
        "            self.img_labels = ['0' for i in range(len(self.img_paths))]\n",
        "            self.domain_labels = ['0' for i in range(len(self.img_paths))]\n",
        "\n",
        "        self.n_data = len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img_paths, labels, domain_labels = self.img_paths[item%self.n_data], self.img_labels[item%self.n_data], self.domain_labels[item%self.n_data]\n",
        "        imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "\n",
        "            if isinstance(self.transform, list):\n",
        "                tform = self.transform[int(domain_labels)]\n",
        "            else:\n",
        "                tform = self.transform\n",
        "\n",
        "            imgs = tform(imgs)\n",
        "            labels = int(labels)\n",
        "            domain_labels = int(domain_labels)\n",
        "\n",
        "        return imgs, labels, domain_labels, img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_data"
      ],
      "metadata": {
        "id": "ZCqhYsWhNlKK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = GetLoader(\n",
        "    data_root=os.path.join(source_image_root, 'train_set'),\n",
        "    data_list=train_label_list,\n",
        "    transform=img_transform\n",
        ")\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    drop_last=False)\n",
        "    \n",
        "test_dataset = GetLoader(\n",
        "    data_root=os.path.join(target_image_root, 'test_set'),\n",
        "    transform=img_transform\n",
        ")\n",
        "\n",
        "test_dataloader = data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    drop_last=False)\n",
        "\n",
        "train_mean = 0.0\n",
        "domain0_mean = 0.0\n",
        "domain1_mean = 0.0\n",
        "domain2_mean = 0.0\n",
        "domain0_count = 0\n",
        "domain1_count = 0\n",
        "domain2_count = 0\n",
        "for images, _, domain_label, _ in tqdm(train_dataloader):\n",
        "    batch_samples = images.size(0) \n",
        "    images = images.view(batch_samples, images.size(1), -1)\n",
        "    train_mean += images.mean(2).sum(0)\n",
        "\n",
        "    domain0_count += (domain_label == 0).nonzero(as_tuple=True)[0].shape[0]\n",
        "    domain1_count += (domain_label == 1).nonzero(as_tuple=True)[0].shape[0]\n",
        "    domain2_count += (domain_label == 2).nonzero(as_tuple=True)[0].shape[0]\n",
        "    domain0_mean += torch.index_select(images, 0, (domain_label == 0).nonzero(as_tuple=True)[0]).mean(2).sum(0)\n",
        "    domain1_mean += torch.index_select(images, 0, (domain_label == 1).nonzero(as_tuple=True)[0]).mean(2).sum(0)\n",
        "    domain2_mean += torch.index_select(images, 0, (domain_label == 2).nonzero(as_tuple=True)[0]).mean(2).sum(0)\n",
        "\n",
        "mean = train_mean / len(train_dataloader.dataset)\n",
        "domain0_mean = domain0_mean / domain0_count\n",
        "domain1_mean = domain1_mean / domain1_count\n",
        "domain2_mean = domain2_mean / domain2_count\n",
        "\n",
        "var = 0.0\n",
        "domain0_var = 0.0\n",
        "domain1_var = 0.0\n",
        "domain2_var = 0.0\n",
        "for images, _, _,_ in tqdm(train_dataloader):\n",
        "    batch_samples = images.size(0)\n",
        "    images = images.view(batch_samples, images.size(1), -1)\n",
        "\n",
        "    var += ((images - mean.unsqueeze(1))**2).sum([0,2])\n",
        "\n",
        "    domain0_var += ((torch.index_select(images, 0, (domain_label == 0).nonzero(as_tuple=True)[0]) - domain0_mean.unsqueeze(1))**2).sum([0,2]) \n",
        "    domain1_var += ((torch.index_select(images, 0, (domain_label == 1).nonzero(as_tuple=True)[0]) - domain1_mean.unsqueeze(1))**2).sum([0,2]) \n",
        "    domain2_var += ((torch.index_select(images, 0, (domain_label == 2).nonzero(as_tuple=True)[0]) - domain2_mean.unsqueeze(1))**2).sum([0,2]) \n",
        "\n",
        "std = torch.sqrt(var / (len(train_dataloader.dataset)*224*224))\n",
        "domain0_std = torch.sqrt(domain0_var / (domain0_count*224*224))\n",
        "domain1_std = torch.sqrt(domain1_var / (domain1_count*224*224))\n",
        "domain2_std = torch.sqrt(domain2_var / (domain2_count*224*224))\n",
        "\n",
        "print('Train size: ', len(train_dataloader.dataset))\n",
        "print('Num Domain 0: ', domain0_count)\n",
        "print('Num Domain 1: ', domain1_count)\n",
        "print('Num Domain 2: ', domain2_count)\n",
        "\n",
        "print('Global train mean: ', mean)\n",
        "print('Global train std: ', std)\n",
        "print('Domain 0 mean: ', domain0_mean)\n",
        "print('Domain 0 std: ', domain0_std)\n",
        "print('Domain 1 mean: ', domain1_mean)\n",
        "print('Domain 1 std: ', domain1_std)\n",
        "print('Domain 2 mean: ', domain2_mean)\n",
        "print('Domain 2 std: ', domain2_std)\n",
        "\n",
        "domain3_mean = 0.0\n",
        "for images, _, domain_label, _ in tqdm(test_dataloader):\n",
        "    batch_samples = images.size(0) \n",
        "    images = images.view(batch_samples, images.size(1), -1)\n",
        "    domain3_mean += images.mean(2).sum(0)\n",
        "    train_mean += images.mean(2).sum(0)\n",
        "\n",
        "domain3_mean = domain3_mean / len(test_dataloader.dataset)\n",
        "global_mean = train_mean/(len(train_dataloader.dataset)+len(test_dataloader.dataset))\n",
        "\n",
        "global_var = 0.0\n",
        "for images, _, _,_ in tqdm(train_dataloader):\n",
        "    batch_samples = images.size(0)\n",
        "    images = images.view(batch_samples, images.size(1), -1)\n",
        "\n",
        "    global_var += ((images - global_mean.unsqueeze(1))**2).sum([0,2])\n",
        "\n",
        "domain3_var = 0.0\n",
        "for images, _, _,_ in tqdm(test_dataloader):\n",
        "    batch_samples = images.size(0)\n",
        "    images = images.view(batch_samples, images.size(1), -1)\n",
        "\n",
        "    domain3_var += ((images - domain3_mean.unsqueeze(1))**2).sum([0,2])\n",
        "    global_var += ((images - global_mean.unsqueeze(1))**2).sum([0,2])\n",
        "\n",
        "domain3_std = torch.sqrt(domain3_var / (len(test_dataloader.dataset)*224*224))\n",
        "global_std = torch.sqrt(global_var / ((len(test_dataloader.dataset)+len(train_dataloader.dataset))*224*224))\n",
        "\n",
        "print('Test size: ', len(test_dataloader.dataset))\n",
        "print('Domain 3 mean: ', domain3_mean)\n",
        "print('Domain 3 std: ', domain3_std)\n",
        "\n",
        "print('Global Mean: ', global_mean)\n",
        "print('Global std: ', global_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFe40O-lNnjl",
        "outputId": "82f0e2fa-c831-4ffc-f88b-e02989cf9522"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [10:43<00:00, 13.40s/it]\n",
            "100%|██████████| 48/48 [00:30<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size:  6062\n",
            "Num Domain 0:  1670\n",
            "Num Domain 1:  2048\n",
            "Num Domain 2:  2344\n",
            "Global train mean:  tensor([0.6399, 0.6076, 0.5603])\n",
            "Global train std:  tensor([0.3065, 0.3082, 0.3353])\n",
            "Domain 0 mean:  tensor([0.5085, 0.4832, 0.4396])\n",
            "Domain 0 std:  tensor([0.1780, 0.1779, 0.1907])\n",
            "Domain 1 mean:  tensor([0.5550, 0.5085, 0.4579])\n",
            "Domain 1 std:  tensor([0.1880, 0.1917, 0.2060])\n",
            "Domain 2 mean:  tensor([0.8077, 0.7829, 0.7358])\n",
            "Domain 2 std:  tensor([0.2239, 0.2283, 0.2437])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [07:43<00:00, 14.95s/it]\n",
            "100%|██████████| 48/48 [00:29<00:00,  1.62it/s]\n",
            "100%|██████████| 31/31 [00:19<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size:  3929\n",
            "Domain 3 mean:  tensor([0.9566, 0.9566, 0.9566])\n",
            "Domain 3 std:  tensor([0.1752, 0.1752, 0.1752])\n",
            "Global Mean:  tensor([0.7645, 0.7449, 0.7162])\n",
            "Global std:  tensor([0.3050, 0.3143, 0.3432])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train size:  6062\n",
        "\n",
        "Num Domain 0:  1670\n",
        "\n",
        "Num Domain 1:  2048\n",
        "\n",
        "Num Domain 2:  2344\n",
        "\n",
        "Global train mean:  tensor([0.6399, 0.6076, 0.5603])\n",
        "\n",
        "Global train std:  tensor([0.3065, 0.3082, 0.3353])\n",
        "\n",
        "Domain 0 mean:  tensor([0.5085, 0.4832, 0.4396])\n",
        "\n",
        "Domain 0 std:  tensor([0.1780, 0.1779, 0.1907])\n",
        "\n",
        "Domain 1 mean:  tensor([0.5550, 0.5085, 0.4579])\n",
        "\n",
        "Domain 1 std:  tensor([0.1880, 0.1917, 0.2060])\n",
        "\n",
        "Domain 2 mean:  tensor([0.8077, 0.7829, 0.7358])\n",
        "\n",
        "Domain 2 std:  tensor([0.2239, 0.2283, 0.2437])\n",
        "\n",
        "Test size:  3929\n",
        "\n",
        "Domain 3 mean:  tensor([0.9566, 0.9566, 0.9566])\n",
        "\n",
        "Domain 3 std:  tensor([0.1752, 0.1752, 0.1752])\n",
        "\n",
        "Global Mean:  tensor([0.7645, 0.7449, 0.7162])\n",
        "\n",
        "Global std:  tensor([0.3050, 0.3143, 0.3432])"
      ],
      "metadata": {
        "id": "fiUghl7zNySG"
      }
    }
  ]
}